
R version 4.3.3 (2024-02-29) -- "Angel Food Cake"
Copyright (C) 2024 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

[Previously saved workspace restored]

> library(patchwork)
> library(loo)
This is loo version 2.8.0
- Online documentation and vignettes at mc-stan.org/loo
- As of v2.0.0 loo defaults to 1 core but we recommend using as many as possible. Use the 'cores' argument or set options(mc.cores = NUM_CORES) for an entire session. 
> library(bayesplot)
This is bayesplot version 1.11.1
- Online documentation and vignettes at mc-stan.org/bayesplot
- bayesplot theme set to bayesplot::theme_default()
   * Does _not_ affect other ggplot2 plots
   * See ?bayesplot_theme_set for details on theme setting
> library(cmdstanr)
This is cmdstanr version 0.8.1
- CmdStanR documentation and vignettes: mc-stan.org/cmdstanr
- CmdStan path: /u/cdslab/scocomello/.cmdstan/cmdstan-2.34.1
- CmdStan version: 2.34.1

A newer version of CmdStan is available. See ?install_cmdstan() to install it.
To disable this check set option or environment variable cmdstanr_no_ver_check=TRUE.
> library(factoextra)
Loading required package: ggplot2
Welcome! Want to learn more? See two factoextra-related books at https://goo.gl/ve3WBa
> library(dplyr)

Attaching package: ‘dplyr’

The following objects are masked from ‘package:stats’:

    filter, lag

The following objects are masked from ‘package:base’:

    intersect, setdiff, setequal, union

> library(stringr)
> 
> 
> #setwd("C:/Users/sarac/CDS_git/Copy-Number-Timing/CopyNumber/")
> #orfeo
> setwd("/orfeo/cephfs/scratch/cdslab/scocomello/Copy_Number_Timing/CopyNumber")
> 
> original_dir <- getwd()
> 
> source("./CNTiming/R/simulate_functions.R")
> source("./CNTiming/R/fitting_functions.R")
> source("./CNTiming/R/plotting_functions.R")
> 
> 
> self_name = "SN_2"
> new_dir = paste0("../",self_name) #relative path of the new created directory where to save the simulation results
> dir.create(new_dir)
> 
> number_events = 30
> number_clocks = 3
> 
> INIT = FALSE
> epsilon = 0.20
> n_simulations = 20
> purity = 0.99
> 
> vector_karyo <- c("2:0", "2:1", "2:2")
> weights_karyo <- c(0.33, 0.33, 0.33)
> 
> options(bitmapType='cairo')
> 
> 
> 
> 
> for(i in 1:n_simulations){
+   # Create a unique directory for each iteration
+   iter_dir <- paste0("/simulation_iteration_", i)
+   iter_dir <- paste0(new_dir,iter_dir)
+   dir.create(iter_dir)
+   setwd(iter_dir)
+   dir.create(paste0("./plots"), showWarnings = TRUE)
+   dir.create(paste0("./results"), showWarnings = FALSE)
+   
+   
+ 
+   vector_tau = rep(0, number_clocks)
+   
+   for (j in 1:number_clocks){
+     vector_tau[j] = runif(1, 0)
+     if (j != 1){
+       while (!all ( abs(vector_tau[1:j-1] - vector_tau[j]) > epsilon  )   ){
+         vector_tau[j] = runif(1, 0)
+       }
+     }
+   }
+   weights_tau <- rep(1/number_clocks, number_clocks)
+   
+   data <- get_taus_karyo(number_events, vector_tau, vector_karyo, weights_tau, weights_karyo)
+   all_sim = get_simulation(data$taus, data$karyo, purity)
+   data_sim <- all_sim
+   #add statistics on number of mutations from the simulation
+   
+   simulation_params <- list(
+     vector_tau = vector_tau,
+     vector_karyo = vector_karyo,
+     weights_tau = weights_tau,
+     weights_karyo = weights_karyo,
+     taus = data$taus,
+     karyo = data$karyo,
+     purity = purity,
+     number_events = number_events,
+     number_clocks = number_clocks,
+     epsilon = epsilon
+   )
+ 
+   data_sim_plot = data_sim %>% mutate (tau = round(tau, 2))
+   plot_data <- data_sim_plot %>% 
+     ggplot(mapping = aes(x = NV / DP, fill = as.factor(j))) +
+     geom_histogram(alpha = .5, position = "identity") +
+     labs(
+       title = "Histogram of the VAF spectrum, per segment"
+     )+
+     facet_wrap(vars(karyotype, tau, j))
+   
+   ggsave("./plots/original_data.png", plot = plot_data, width = 12 +  simulation_params$number_events, height = 10 + simulation_params$number_events + (simulation_params$number_events/1.3), limitsize = FALSE,   device = png)
+   #simulation_params can be substituted in relation with data_sim variables
+   
+   
+   #in "fit model selection best K" the plots for each K inference is directly saved 
+   results <- fit_model_selection_best_K(data_sim, data$karyo, purity, INIT = INIT, simulation_params = simulation_params)
+   
+   
+   
+   
+   
+   
+   
+   model_selection <- results$model_selection_tibble
+   best_K <- results$best_K
+   
+   
+   bic_plot <- ggplot(data = model_selection, aes(x = K, y = BIC)) + 
+     geom_line(aes(colour = "BIC Line")) + 
+     geom_point(aes(colour = "BIC Point")) +
+     geom_point(aes(x = best_K, y = BIC[K == best_K], colour = "Best K Point")) +
+     geom_point(aes(x = K[BIC == min(BIC)], y = min(BIC), colour = "Minimum Point")) +
+     scale_colour_manual(name = "Legend",
+                         values = c("BIC Line" = "blue", 
+                                    "BIC Point" = "blue", 
+                                    "Best K Point" = "red",
+                                    "Minimum Point" = "green"),)
+   
+   aic_plot <- ggplot(data = model_selection, aes(x = K, y = AIC)) + 
+     geom_line(aes(colour = "AIC Line")) + 
+     geom_point(aes(colour = "AIC Point")) +
+     geom_point(aes(x = best_K, y = AIC[K == best_K], colour = "Best K Point")) +
+     geom_point(aes(x = K[AIC == min(AIC)], y = min(AIC), colour = "Minimum Point")) +
+     scale_colour_manual(name = "Legend",
+                         values = c("AIC Line" = "blue", 
+                                    "AIC Point" = "blue", 
+                                    "Best K Point" = "red",
+                                    "Minimum Point" = "green"))
+   
+ 
+   loo_plot <- ggplot(data = model_selection, aes(x = K, y = LOO)) + 
+     geom_line(aes(colour = "LOO Line")) + 
+     geom_point(aes(colour = "LOO Point")) +
+     geom_point(aes(x = best_K, y = LOO[K == best_K], colour = "Best K Point")) +
+     geom_point(aes(x = K[LOO == min(LOO)], y = min(LOO), colour = "Minimum Point")) +
+     scale_colour_manual(name = "Legend",
+                         values = c("LOO Line" = "blue", 
+                                    "LOO Point" = "blue", 
+                                    "Best K Point" = "red",
+                                    "Minimum Point" = "green"))
+   
+   
+   log_lik_plot <- ggplot(data = model_selection, aes(x = K, y = Log_lik)) + 
+     geom_line(aes(colour = "Log likelihood Line")) + 
+     geom_point(aes(colour = "Log likelihood Point")) +
+     geom_point(aes(x = best_K, y = Log_lik[K == best_K], colour = "Best K Point")) +
+     geom_point(aes(x = K[Log_lik == max(Log_lik)], y = max(Log_lik), colour = "Minimum Point")) +
+     scale_colour_manual(name = "Legend",
+                         values = c("Log likelihood Line" = "blue", 
+                                    "Log likelihood Point" = "blue", 
+                                    "Best K Point" = "red",
+                                    "Minimum Point" = "green"))
+   
+   
+   
+   Subtitle <- vector("list", S)
+   
+   for (i in 1:S) {
+     n_parameters <- i+(i*S)+2
+     Subtitle[[i]] <- paste0(" ", i, ": ", n_parameters," parameters")
+   }
+   
+   Subtitle <- paste(Subtitle, collapse = "\n")
+   
+   
+   
+   
+   model_selection_plot <- (bic_plot | aic_plot) / (loo_plot|log_lik_plot) +
+   plot_annotation(
+     title = "Model selection graphs: score vs number of clusters" ,
+     subtitle = paste0 ("Correspondence between number of clusters and number of parameters:  \n", Subtitle),
+     caption = "caption"
+   ) & theme(text = element_text(size = 8), plot.title = element_text(size = 10), plot.subtitle = element_text(size = 8), axis.text = element_text(size = 8), plot.caption = element_text(size = 5))
+   
+   
+   
+   
+   ggsave("./plots/model_selection_plot.png", plot = model_selection_plot, width = 12, height = 10,  device = png)
+   saveRDS(model_selection, "./results/model_selection.rds")
+   
+   
+   
+   setwd(original_dir)
+   
+ }
[1] 0.300568
[1] 0.09472414
[1] 0.09472414
[1] 0.09472414
[1] 0.5818229
[1] 0.300568
[1] 0.300568
[1] 0.5818229
[1] 0.300568
[1] 0.300568
[1] 0.09472414
[1] 0.300568
[1] 0.300568
[1] 0.300568
[1] 0.09472414
[1] 0.5818229
[1] 0.09472414
[1] 0.300568
[1] 0.300568
[1] 0.5818229
[1] 0.09472414
[1] 0.5818229
[1] 0.5818229
[1] 0.300568
[1] 0.300568
[1] 0.09472414
[1] 0.5818229
[1] 0.09472414
[1] 0.5818229
[1] 0.09472414
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
Attempt 1 with 10000 iterations, 1 grad_samples, and 100 elbo_samples
------------------------------------------------------------ 
EXPERIMENTAL ALGORITHM: 
  This procedure has not been thoroughly tested and may be unstable 
  or buggy. The interface is subject to change. 
------------------------------------------------------------ 
Gradient evaluation took 0.013698 seconds 
1000 transitions using 10 leapfrog steps per transition would take 136.98 seconds. 
Adjust your expectations accordingly! 
Begin eta adaptation. 
Iteration:   1 / 250 [  0%]  (Adaptation) 
Iteration:  50 / 250 [ 20%]  (Adaptation) 
Iteration: 100 / 250 [ 40%]  (Adaptation) 
Iteration: 150 / 250 [ 60%]  (Adaptation) 
Iteration: 200 / 250 [ 80%]  (Adaptation) 
Success! Found best value [eta = 1] earlier than expected. 
Begin stochastic gradient ascent. 
  iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  
   100       -49953.119             1.000            1.000 
   200       -49950.139             0.500            1.000 
   300       -49945.958             0.333            0.000   MEDIAN ELBO CONVERGED 
Drawing a sample of size 1000 from the approximate posterior...  
COMPLETED. 
Finished in  38.1 seconds.
Fit succeeded in attempt 1
Inference completed successfully.
Scale for x is already present.
Adding another scale for x, which will replace the existing scale.
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
Attempt 1 with 10000 iterations, 1 grad_samples, and 100 elbo_samples
------------------------------------------------------------ 
EXPERIMENTAL ALGORITHM: 
  This procedure has not been thoroughly tested and may be unstable 
  or buggy. The interface is subject to change. 
------------------------------------------------------------ 
Gradient evaluation took 0.021769 seconds 
1000 transitions using 10 leapfrog steps per transition would take 217.69 seconds. 
Adjust your expectations accordingly! 
Begin eta adaptation. 
Iteration:   1 / 250 [  0%]  (Adaptation) 
Iteration:  50 / 250 [ 20%]  (Adaptation) 
Iteration: 100 / 250 [ 40%]  (Adaptation) 
Iteration: 150 / 250 [ 60%]  (Adaptation) 
Iteration: 200 / 250 [ 80%]  (Adaptation) 
Success! Found best value [eta = 1] earlier than expected. 
Begin stochastic gradient ascent. 
  iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  
   100       -49405.646             1.000            1.000 
   200       -49406.379             0.500            1.000 
   300       -49404.152             0.333            0.000   MEDIAN ELBO CONVERGED 
Drawing a sample of size 1000 from the approximate posterior...  
COMPLETED. 
Finished in  53.9 seconds.
Fit succeeded in attempt 1
Inference completed successfully.
Scale for x is already present.
Adding another scale for x, which will replace the existing scale.
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
Attempt 1 with 10000 iterations, 1 grad_samples, and 100 elbo_samples
------------------------------------------------------------ 
EXPERIMENTAL ALGORITHM: 
  This procedure has not been thoroughly tested and may be unstable 
  or buggy. The interface is subject to change. 
------------------------------------------------------------ 
Gradient evaluation took 0.032413 seconds 
1000 transitions using 10 leapfrog steps per transition would take 324.13 seconds. 
Adjust your expectations accordingly! 
Begin eta adaptation. 
Iteration:   1 / 250 [  0%]  (Adaptation) 
Iteration:  50 / 250 [ 20%]  (Adaptation) 
Iteration: 100 / 250 [ 40%]  (Adaptation) 
Iteration: 150 / 250 [ 60%]  (Adaptation) 
Iteration: 200 / 250 [ 80%]  (Adaptation) 
Success! Found best value [eta = 1] earlier than expected. 
Begin stochastic gradient ascent. 
  iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  
   100       -49429.918             1.000            1.000 
   200       -49411.106             0.500            1.000 
   300       -49412.679             0.333            0.000   MEDIAN ELBO CONVERGED 
Drawing a sample of size 1000 from the approximate posterior...  
COMPLETED. 
Finished in  59.7 seconds.
Fit succeeded in attempt 1
Inference completed successfully.
Scale for x is already present.
Adding another scale for x, which will replace the existing scale.
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
Attempt 1 with 10000 iterations, 1 grad_samples, and 100 elbo_samples
------------------------------------------------------------ 
EXPERIMENTAL ALGORITHM: 
  This procedure has not been thoroughly tested and may be unstable 
  or buggy. The interface is subject to change. 
------------------------------------------------------------ 
Gradient evaluation took 0.041798 seconds 
1000 transitions using 10 leapfrog steps per transition would take 417.98 seconds. 
Adjust your expectations accordingly! 
Begin eta adaptation. 
Iteration:   1 / 250 [  0%]  (Adaptation) 
Iteration:  50 / 250 [ 20%]  (Adaptation) 
Iteration: 100 / 250 [ 40%]  (Adaptation) 
Iteration: 150 / 250 [ 60%]  (Adaptation) 
Iteration: 200 / 250 [ 80%]  (Adaptation) 
Success! Found best value [eta = 1] earlier than expected. 
Begin stochastic gradient ascent. 
  iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  
   100       -49464.218             1.000            1.000 
   200       -49443.306             0.500            1.000 
   300       -49438.819             0.334            0.000   MEDIAN ELBO CONVERGED 
Drawing a sample of size 1000 from the approximate posterior...  
COMPLETED. 
Finished in  73.0 seconds.
Fit succeeded in attempt 1
Inference completed successfully.
Scale for x is already present.
Adding another scale for x, which will replace the existing scale.
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
Attempt 1 with 10000 iterations, 1 grad_samples, and 100 elbo_samples
------------------------------------------------------------ 
EXPERIMENTAL ALGORITHM: 
  This procedure has not been thoroughly tested and may be unstable 
  or buggy. The interface is subject to change. 
------------------------------------------------------------ 
Gradient evaluation took 0.054008 seconds 
1000 transitions using 10 leapfrog steps per transition would take 540.08 seconds. 
Adjust your expectations accordingly! 
Begin eta adaptation. 
Iteration:   1 / 250 [  0%]  (Adaptation) 
Iteration:  50 / 250 [ 20%]  (Adaptation) 
Iteration: 100 / 250 [ 40%]  (Adaptation) 
Iteration: 150 / 250 [ 60%]  (Adaptation) 
Iteration: 200 / 250 [ 80%]  (Adaptation) 
Success! Found best value [eta = 1] earlier than expected. 
Begin stochastic gradient ascent. 
  iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  
   100       -49476.672             1.000            1.000 
   200       -49463.124             0.500            1.000 
   300       -49441.605             0.334            0.000   MEDIAN ELBO CONVERGED 
Drawing a sample of size 1000 from the approximate posterior...  
COMPLETED. 
Finished in  84.5 seconds.
Fit succeeded in attempt 1
Inference completed successfully.
Scale for x is already present.
Adding another scale for x, which will replace the existing scale.
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
Attempt 1 with 10000 iterations, 1 grad_samples, and 100 elbo_samples
------------------------------------------------------------ 
EXPERIMENTAL ALGORITHM: 
  This procedure has not been thoroughly tested and may be unstable 
  or buggy. The interface is subject to change. 
------------------------------------------------------------ 
Gradient evaluation took 0.064452 seconds 
1000 transitions using 10 leapfrog steps per transition would take 644.52 seconds. 
Adjust your expectations accordingly! 
Begin eta adaptation. 
Iteration:   1 / 250 [  0%]  (Adaptation) 
Iteration:  50 / 250 [ 20%]  (Adaptation) 
Iteration: 100 / 250 [ 40%]  (Adaptation) 
Iteration: 150 / 250 [ 60%]  (Adaptation) 
Iteration: 200 / 250 [ 80%]  (Adaptation) 
Success! Found best value [eta = 1] earlier than expected. 
Begin stochastic gradient ascent. 
  iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  
   100       -49480.842             1.000            1.000 
   200       -49471.550             0.500            1.000 
   300       -49478.721             0.333            0.000   MEDIAN ELBO CONVERGED 
Drawing a sample of size 1000 from the approximate posterior...  
COMPLETED. 
Finished in  106.2 seconds.
Fit succeeded in attempt 1
Inference completed successfully.
Scale for x is already present.
Adding another scale for x, which will replace the existing scale.
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
Attempt 1 with 10000 iterations, 1 grad_samples, and 100 elbo_samples
------------------------------------------------------------ 
EXPERIMENTAL ALGORITHM: 
  This procedure has not been thoroughly tested and may be unstable 
  or buggy. The interface is subject to change. 
------------------------------------------------------------ 
Gradient evaluation took 0.073626 seconds 
1000 transitions using 10 leapfrog steps per transition would take 736.26 seconds. 
Adjust your expectations accordingly! 
Begin eta adaptation. 
Iteration:   1 / 250 [  0%]  (Adaptation) 
Iteration:  50 / 250 [ 20%]  (Adaptation) 
Iteration: 100 / 250 [ 40%]  (Adaptation) 
Iteration: 150 / 250 [ 60%]  (Adaptation) 
Iteration: 200 / 250 [ 80%]  (Adaptation) 
Success! Found best value [eta = 1] earlier than expected. 
Begin stochastic gradient ascent. 
  iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  
   100       -49463.403             1.000            1.000 
   200       -49452.748             0.500            1.000 
   300       -49455.942             0.333            0.000   MEDIAN ELBO CONVERGED 
Drawing a sample of size 1000 from the approximate posterior...  
COMPLETED. 
Finished in  109.6 seconds.
Fit succeeded in attempt 1
Inference completed successfully.
Scale for x is already present.
Adding another scale for x, which will replace the existing scale.
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
Attempt 1 with 10000 iterations, 1 grad_samples, and 100 elbo_samples
------------------------------------------------------------ 
EXPERIMENTAL ALGORITHM: 
  This procedure has not been thoroughly tested and may be unstable 
  or buggy. The interface is subject to change. 
------------------------------------------------------------ 
Gradient evaluation took 0.082458 seconds 
1000 transitions using 10 leapfrog steps per transition would take 824.58 seconds. 
Adjust your expectations accordingly! 
Begin eta adaptation. 
Iteration:   1 / 250 [  0%]  (Adaptation) 
Iteration:  50 / 250 [ 20%]  (Adaptation) 
Iteration: 100 / 250 [ 40%]  (Adaptation) 
Iteration: 150 / 250 [ 60%]  (Adaptation) 
Iteration: 200 / 250 [ 80%]  (Adaptation) 
Success! Found best value [eta = 1] earlier than expected. 
Begin stochastic gradient ascent. 
  iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  
   100       -49504.206             1.000            1.000 
   200       -49466.021             0.500            1.000 
   300       -49453.361             0.334            0.001   MEDIAN ELBO CONVERGED 
Drawing a sample of size 1000 from the approximate posterior...  
COMPLETED. 
Finished in  120.4 seconds.
Fit succeeded in attempt 1
Inference completed successfully.
Scale for x is already present.
Adding another scale for x, which will replace the existing scale.
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
Attempt 1 with 10000 iterations, 1 grad_samples, and 100 elbo_samples
------------------------------------------------------------ 
EXPERIMENTAL ALGORITHM: 
  This procedure has not been thoroughly tested and may be unstable 
  or buggy. The interface is subject to change. 
------------------------------------------------------------ 
Gradient evaluation took 0.101215 seconds 
1000 transitions using 10 leapfrog steps per transition would take 1012.15 seconds. 
Adjust your expectations accordingly! 
Begin eta adaptation. 
Iteration:   1 / 250 [  0%]  (Adaptation) 
Iteration:  50 / 250 [ 20%]  (Adaptation) 
Iteration: 100 / 250 [ 40%]  (Adaptation) 
Iteration: 150 / 250 [ 60%]  (Adaptation) 
Iteration: 200 / 250 [ 80%]  (Adaptation) 
Success! Found best value [eta = 1] earlier than expected. 
Begin stochastic gradient ascent. 
  iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  
   100       -49513.994             1.000            1.000 
   200       -49495.026             0.500            1.000 
   300       -49484.675             0.334            0.000   MEDIAN ELBO CONVERGED 
Drawing a sample of size 1000 from the approximate posterior...  
COMPLETED. 
Finished in  141.5 seconds.
An error occurred during inference: Fit failed: draws contain NAs.
Attempt 2 with 10000 iterations, 2 grad_samples, and 200 elbo_samples
------------------------------------------------------------ 
EXPERIMENTAL ALGORITHM: 
  This procedure has not been thoroughly tested and may be unstable 
  or buggy. The interface is subject to change. 
------------------------------------------------------------ 
Gradient evaluation took 0.100788 seconds 
1000 transitions using 10 leapfrog steps per transition would take 1007.88 seconds. 
Adjust your expectations accordingly! 
Begin eta adaptation. 
Iteration:   1 / 250 [  0%]  (Adaptation) 
Iteration:  50 / 250 [ 20%]  (Adaptation) 
Iteration: 100 / 250 [ 40%]  (Adaptation) 
Iteration: 150 / 250 [ 60%]  (Adaptation) 
Iteration: 200 / 250 [ 80%]  (Adaptation) 
Success! Found best value [eta = 1] earlier than expected. 
Begin stochastic gradient ascent. 
  iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  
   100       -49502.633             1.000            1.000 
   200       -49471.656             0.500            1.000 
   300       -49466.715             0.334            0.001   MEDIAN ELBO CONVERGED 
Drawing a sample of size 1000 from the approximate posterior...  
COMPLETED. 
Finished in  176.9 seconds.
Fit succeeded in attempt 2
Inference completed successfully.
Scale for x is already present.
Adding another scale for x, which will replace the existing scale.
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
Attempt 1 with 10000 iterations, 1 grad_samples, and 100 elbo_samples
------------------------------------------------------------ 
EXPERIMENTAL ALGORITHM: 
  This procedure has not been thoroughly tested and may be unstable 
  or buggy. The interface is subject to change. 
------------------------------------------------------------ 
Gradient evaluation took 0.108489 seconds 
1000 transitions using 10 leapfrog steps per transition would take 1084.89 seconds. 
Adjust your expectations accordingly! 
Begin eta adaptation. 
Iteration:   1 / 250 [  0%]  (Adaptation) 
Iteration:  50 / 250 [ 20%]  (Adaptation) 
Iteration: 100 / 250 [ 40%]  (Adaptation) 
Iteration: 150 / 250 [ 60%]  (Adaptation) 
Iteration: 200 / 250 [ 80%]  (Adaptation) 
Success! Found best value [eta = 1] earlier than expected. 
Begin stochastic gradient ascent. 
  iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  
   100       -49532.244             1.000            1.000 
Chain 1 stan::variational::normal_meanfield::calc_grad: The number of dropped evaluations has reached its maximum amount (10). Your model may be either severely ill-conditioned or misspecified.
Warning: Fitting finished unexpectedly! Use the $output() method for more information.

Finished in  47.0 seconds.
An error occurred during inference: Fit failed: Maximum number of discarded evaluations reached.
Attempt 2 with 10000 iterations, 2 grad_samples, and 200 elbo_samples
------------------------------------------------------------ 
EXPERIMENTAL ALGORITHM: 
  This procedure has not been thoroughly tested and may be unstable 
  or buggy. The interface is subject to change. 
------------------------------------------------------------ 
Gradient evaluation took 0.108928 seconds 
1000 transitions using 10 leapfrog steps per transition would take 1089.28 seconds. 
Adjust your expectations accordingly! 
Begin eta adaptation. 
Iteration:   1 / 250 [  0%]  (Adaptation) 
Iteration:  50 / 250 [ 20%]  (Adaptation) 
Iteration: 100 / 250 [ 40%]  (Adaptation) 
Iteration: 150 / 250 [ 60%]  (Adaptation) 
Iteration: 200 / 250 [ 80%]  (Adaptation) 
Success! Found best value [eta = 1] earlier than expected. 
Begin stochastic gradient ascent. 
  iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  
   100       -49529.634             1.000            1.000 
   200       -49511.255             0.500            1.000 
   300       -49500.256             0.334            0.000   MEDIAN ELBO CONVERGED 
Drawing a sample of size 1000 from the approximate posterior...  
COMPLETED. 
Finished in  193.4 seconds.
Fit succeeded in attempt 2
Inference completed successfully.
Scale for x is already present.
Adding another scale for x, which will replace the existing scale.
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
Attempt 1 with 10000 iterations, 1 grad_samples, and 100 elbo_samples
------------------------------------------------------------ 
EXPERIMENTAL ALGORITHM: 
  This procedure has not been thoroughly tested and may be unstable 
  or buggy. The interface is subject to change. 
------------------------------------------------------------ 
Gradient evaluation took 0.119925 seconds 
1000 transitions using 10 leapfrog steps per transition would take 1199.25 seconds. 
Adjust your expectations accordingly! 
Begin eta adaptation. 
Iteration:   1 / 250 [  0%]  (Adaptation) 
Iteration:  50 / 250 [ 20%]  (Adaptation) 
Iteration: 100 / 250 [ 40%]  (Adaptation) 
Iteration: 150 / 250 [ 60%]  (Adaptation) 
Iteration: 200 / 250 [ 80%]  (Adaptation) 
Success! Found best value [eta = 1] earlier than expected. 
Begin stochastic gradient ascent. 
  iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  
Chain 1 stan::variational::advi::calc_ELBO: The number of dropped evaluations has reached its maximum amount (100). Your model may be either severely ill-conditioned or misspecified.
Warning: Fitting finished unexpectedly! Use the $output() method for more information.

Finished in  37.4 seconds.
An error occurred during inference: Fit failed: Maximum number of discarded evaluations reached.
Attempt 2 with 10000 iterations, 2 grad_samples, and 200 elbo_samples
------------------------------------------------------------ 
EXPERIMENTAL ALGORITHM: 
  This procedure has not been thoroughly tested and may be unstable 
  or buggy. The interface is subject to change. 
------------------------------------------------------------ 
Gradient evaluation took 0.116462 seconds 
1000 transitions using 10 leapfrog steps per transition would take 1164.62 seconds. 
Adjust your expectations accordingly! 
Begin eta adaptation. 
Iteration:   1 / 250 [  0%]  (Adaptation) 
Iteration:  50 / 250 [ 20%]  (Adaptation) 
Iteration: 100 / 250 [ 40%]  (Adaptation) 
Iteration: 150 / 250 [ 60%]  (Adaptation) 
Iteration: 200 / 250 [ 80%]  (Adaptation) 
Success! Found best value [eta = 1] earlier than expected. 
Begin stochastic gradient ascent. 
  iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  
   100       -49541.847             1.000            1.000 
   200       -49527.803             0.500            1.000 
   300       -49518.074             0.333            0.000   MEDIAN ELBO CONVERGED 
Drawing a sample of size 1000 from the approximate posterior...  
COMPLETED. 
Finished in  216.0 seconds.
Fit succeeded in attempt 2
Inference completed successfully.
Scale for x is already present.
Adding another scale for x, which will replace the existing scale.
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
Attempt 1 with 10000 iterations, 1 grad_samples, and 100 elbo_samples
------------------------------------------------------------ 
EXPERIMENTAL ALGORITHM: 
  This procedure has not been thoroughly tested and may be unstable 
  or buggy. The interface is subject to change. 
------------------------------------------------------------ 
Gradient evaluation took 0.128003 seconds 
1000 transitions using 10 leapfrog steps per transition would take 1280.03 seconds. 
Adjust your expectations accordingly! 
Begin eta adaptation. 
Iteration:   1 / 250 [  0%]  (Adaptation) 
Iteration:  50 / 250 [ 20%]  (Adaptation) 
Iteration: 100 / 250 [ 40%]  (Adaptation) 
Iteration: 150 / 250 [ 60%]  (Adaptation) 
Iteration: 200 / 250 [ 80%]  (Adaptation) 
Success! Found best value [eta = 1] earlier than expected. 
Begin stochastic gradient ascent. 
  iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  
   100       -49560.630             1.000            1.000 
Chain 1 stan::variational::normal_meanfield::calc_grad: The number of dropped evaluations has reached its maximum amount (10). Your model may be either severely ill-conditioned or misspecified.
Warning: Fitting finished unexpectedly! Use the $output() method for more information.

Finished in  46.4 seconds.
An error occurred during inference: Fit failed: Maximum number of discarded evaluations reached.
Attempt 2 with 10000 iterations, 2 grad_samples, and 200 elbo_samples
------------------------------------------------------------ 
EXPERIMENTAL ALGORITHM: 
  This procedure has not been thoroughly tested and may be unstable 
  or buggy. The interface is subject to change. 
------------------------------------------------------------ 
Gradient evaluation took 0.128972 seconds 
1000 transitions using 10 leapfrog steps per transition would take 1289.72 seconds. 
Adjust your expectations accordingly! 
Begin eta adaptation. 
Iteration:   1 / 250 [  0%]  (Adaptation) 
Iteration:  50 / 250 [ 20%]  (Adaptation) 
Iteration: 100 / 250 [ 40%]  (Adaptation) 
Iteration: 150 / 250 [ 60%]  (Adaptation) 
Iteration: 200 / 250 [ 80%]  (Adaptation) 
Success! Found best value [eta = 1] earlier than expected. 
Begin stochastic gradient ascent. 
  iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  
   100       -49507.464             1.000            1.000 
   200       -49480.615             0.500            1.000 
Chain 1 stan::variational::advi::calc_ELBO: The number of dropped evaluations has reached its maximum amount (200). Your model may be either severely ill-conditioned or misspecified.
Warning: Fitting finished unexpectedly! Use the $output() method for more information.

Finished in  233.3 seconds.
An error occurred during inference: Fit failed: Maximum number of discarded evaluations reached.
Attempt 3 with 10000 iterations, 4 grad_samples, and 400 elbo_samples
------------------------------------------------------------ 
EXPERIMENTAL ALGORITHM: 
  This procedure has not been thoroughly tested and may be unstable 
  or buggy. The interface is subject to change. 
------------------------------------------------------------ 
Gradient evaluation took 0.127733 seconds 
1000 transitions using 10 leapfrog steps per transition would take 1277.33 seconds. 
Adjust your expectations accordingly! 
Begin eta adaptation. 
Iteration:   1 / 250 [  0%]  (Adaptation) 
Iteration:  50 / 250 [ 20%]  (Adaptation) 
Iteration: 100 / 250 [ 40%]  (Adaptation) 
Iteration: 150 / 250 [ 60%]  (Adaptation) 
Iteration: 200 / 250 [ 80%]  (Adaptation) 
Success! Found best value [eta = 1] earlier than expected. 
Begin stochastic gradient ascent. 
  iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  
   100       -49554.914             1.000            1.000 
Chain 1 stan::variational::advi::calc_ELBO: The number of dropped evaluations has reached its maximum amount (400). Your model may be either severely ill-conditioned or misspecified.
Warning: Fitting finished unexpectedly! Use the $output() method for more information.

Finished in  227.4 seconds.
An error occurred during inference: Fit failed: Maximum number of discarded evaluations reached.
Attempt 4 with 10000 iterations, 8 grad_samples, and 800 elbo_samples
------------------------------------------------------------ 
EXPERIMENTAL ALGORITHM: 
  This procedure has not been thoroughly tested and may be unstable 
  or buggy. The interface is subject to change. 
------------------------------------------------------------ 
Gradient evaluation took 0.127452 seconds 
1000 transitions using 10 leapfrog steps per transition would take 1274.52 seconds. 
Adjust your expectations accordingly! 
Begin eta adaptation. 
Iteration:   1 / 250 [  0%]  (Adaptation) 
Iteration:  50 / 250 [ 20%]  (Adaptation) 
Iteration: 100 / 250 [ 40%]  (Adaptation) 
Iteration: 150 / 250 [ 60%]  (Adaptation) 
Iteration: 200 / 250 [ 80%]  (Adaptation) 
Success! Found best value [eta = 1] earlier than expected. 
Begin stochastic gradient ascent. 
  iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  
   100       -49544.208             1.000            1.000 
   200       -49533.174             0.500            1.000 
   300       -49512.171             0.334            0.000   MEDIAN ELBO CONVERGED 
Drawing a sample of size 1000 from the approximate posterior...  
COMPLETED. 
Finished in  748.6 seconds.
Fit succeeded in attempt 4
Inference completed successfully.
Scale for x is already present.
Adding another scale for x, which will replace the existing scale.
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
Attempt 1 with 10000 iterations, 1 grad_samples, and 100 elbo_samples
------------------------------------------------------------ 
EXPERIMENTAL ALGORITHM: 
  This procedure has not been thoroughly tested and may be unstable 
  or buggy. The interface is subject to change. 
------------------------------------------------------------ 
Gradient evaluation took 0.137653 seconds 
1000 transitions using 10 leapfrog steps per transition would take 1376.53 seconds. 
Adjust your expectations accordingly! 
Begin eta adaptation. 
Iteration:   1 / 250 [  0%]  (Adaptation) 
Iteration:  50 / 250 [ 20%]  (Adaptation) 
Iteration: 100 / 250 [ 40%]  (Adaptation) 
Iteration: 150 / 250 [ 60%]  (Adaptation) 
Iteration: 200 / 250 [ 80%]  (Adaptation) 
Success! Found best value [eta = 1] earlier than expected. 
Begin stochastic gradient ascent. 
  iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  
   100       -49563.596             1.000            1.000 
Chain 1 stan::variational::normal_meanfield::calc_grad: The number of dropped evaluations has reached its maximum amount (10). Your model may be either severely ill-conditioned or misspecified.
Warning: Fitting finished unexpectedly! Use the $output() method for more information.

Finished in  53.6 seconds.
An error occurred during inference: Fit failed: Maximum number of discarded evaluations reached.
Attempt 2 with 10000 iterations, 2 grad_samples, and 200 elbo_samples
------------------------------------------------------------ 
EXPERIMENTAL ALGORITHM: 
  This procedure has not been thoroughly tested and may be unstable 
  or buggy. The interface is subject to change. 
------------------------------------------------------------ 
Gradient evaluation took 0.136691 seconds 
1000 transitions using 10 leapfrog steps per transition would take 1366.91 seconds. 
Adjust your expectations accordingly! 
Begin eta adaptation. 
Iteration:   1 / 250 [  0%]  (Adaptation) 
Iteration:  50 / 250 [ 20%]  (Adaptation) 
Iteration: 100 / 250 [ 40%]  (Adaptation) 
Iteration: 150 / 250 [ 60%]  (Adaptation) 
Iteration: 200 / 250 [ 80%]  (Adaptation) 
Success! Found best value [eta = 1] earlier than expected. 
Begin stochastic gradient ascent. 
  iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  
   100       -49533.128             1.000            1.000 
Chain 1 stan::variational::normal_meanfield::calc_grad: The number of dropped evaluations has reached its maximum amount (20). Your model may be either severely ill-conditioned or misspecified.
Warning: Fitting finished unexpectedly! Use the $output() method for more information.

Finished in  106.9 seconds.
An error occurred during inference: Fit failed: Maximum number of discarded evaluations reached.
Attempt 3 with 10000 iterations, 4 grad_samples, and 400 elbo_samples
------------------------------------------------------------ 
EXPERIMENTAL ALGORITHM: 
  This procedure has not been thoroughly tested and may be unstable 
  or buggy. The interface is subject to change. 
------------------------------------------------------------ 
Gradient evaluation took 0.138738 seconds 
1000 transitions using 10 leapfrog steps per transition would take 1387.38 seconds. 
Adjust your expectations accordingly! 
Begin eta adaptation. 
Iteration:   1 / 250 [  0%]  (Adaptation) 
Iteration:  50 / 250 [ 20%]  (Adaptation) 
Iteration: 100 / 250 [ 40%]  (Adaptation) 
Iteration: 150 / 250 [ 60%]  (Adaptation) 
Iteration: 200 / 250 [ 80%]  (Adaptation) 
Success! Found best value [eta = 1] earlier than expected. 
Begin stochastic gradient ascent. 
  iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  
   100       -49549.869             1.000            1.000 
   200       -49530.574             0.500            1.000 
   300       -49524.313             0.334            0.000   MEDIAN ELBO CONVERGED 
Drawing a sample of size 1000 from the approximate posterior...  
COMPLETED. 
Finished in  373.9 seconds.
Fit succeeded in attempt 3
Inference completed successfully.
Scale for x is already present.
Adding another scale for x, which will replace the existing scale.
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
Attempt 1 with 10000 iterations, 1 grad_samples, and 100 elbo_samples
------------------------------------------------------------ 
EXPERIMENTAL ALGORITHM: 
  This procedure has not been thoroughly tested and may be unstable 
  or buggy. The interface is subject to change. 
------------------------------------------------------------ 
Gradient evaluation took 0.148157 seconds 
1000 transitions using 10 leapfrog steps per transition would take 1481.57 seconds. 
Adjust your expectations accordingly! 
Begin eta adaptation. 
Iteration:   1 / 250 [  0%]  (Adaptation) 
Iteration:  50 / 250 [ 20%]  (Adaptation) 
Iteration: 100 / 250 [ 40%]  (Adaptation) 
Iteration: 150 / 250 [ 60%]  (Adaptation) 
Iteration: 200 / 250 [ 80%]  (Adaptation) 
Success! Found best value [eta = 1] earlier than expected. 
Begin stochastic gradient ascent. 
  iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  
Chain 1 stan::variational::advi::calc_ELBO: The number of dropped evaluations has reached its maximum amount (100). Your model may be either severely ill-conditioned or misspecified.
Warning: Fitting finished unexpectedly! Use the $output() method for more information.

Finished in  51.2 seconds.
An error occurred during inference: Fit failed: Maximum number of discarded evaluations reached.
Attempt 2 with 10000 iterations, 2 grad_samples, and 200 elbo_samples
------------------------------------------------------------ 
EXPERIMENTAL ALGORITHM: 
  This procedure has not been thoroughly tested and may be unstable 
  or buggy. The interface is subject to change. 
------------------------------------------------------------ 
Gradient evaluation took 0.146035 seconds 
1000 transitions using 10 leapfrog steps per transition would take 1460.35 seconds. 
Adjust your expectations accordingly! 
Begin eta adaptation. 
Iteration:   1 / 250 [  0%]  (Adaptation) 
Iteration:  50 / 250 [ 20%]  (Adaptation) 
Iteration: 100 / 250 [ 40%]  (Adaptation) 
Iteration: 150 / 250 [ 60%]  (Adaptation) 
Iteration: 200 / 250 [ 80%]  (Adaptation) 
Success! Found best value [eta = 1] earlier than expected. 
Begin stochastic gradient ascent. 
  iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  
Chain 1 stan::variational::normal_meanfield::calc_grad: The number of dropped evaluations has reached its maximum amount (20). Your model may be either severely ill-conditioned or misspecified.
Warning: Fitting finished unexpectedly! Use the $output() method for more information.

Finished in  80.6 seconds.
An error occurred during inference: Fit failed: Maximum number of discarded evaluations reached.
Attempt 3 with 10000 iterations, 4 grad_samples, and 400 elbo_samples
------------------------------------------------------------ 
EXPERIMENTAL ALGORITHM: 
  This procedure has not been thoroughly tested and may be unstable 
  or buggy. The interface is subject to change. 
------------------------------------------------------------ 
Gradient evaluation took 0.147257 seconds 
1000 transitions using 10 leapfrog steps per transition would take 1472.57 seconds. 
Adjust your expectations accordingly! 
Begin eta adaptation. 
Iteration:   1 / 250 [  0%]  (Adaptation) 
Iteration:  50 / 250 [ 20%]  (Adaptation) 
Iteration: 100 / 250 [ 40%]  (Adaptation) 
Iteration: 150 / 250 [ 60%]  (Adaptation) 
Iteration: 200 / 250 [ 80%]  (Adaptation) 
Iteration: 250 / 250 [100%]  (Adaptation) 
Success! Found best value [eta = 0.1]. 
Begin stochastic gradient ascent. 
  iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  
   100       -50036.265             1.000            1.000 
   200       -49769.078             0.503            1.000 
   300       -49670.942             0.336            0.005   MEDIAN ELBO CONVERGED 
Drawing a sample of size 1000 from the approximate posterior...  
COMPLETED. 
Finished in  454.1 seconds.
Fit succeeded in attempt 3
Inference completed successfully.
Scale for x is already present.
Adding another scale for x, which will replace the existing scale.
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
Attempt 1 with 10000 iterations, 1 grad_samples, and 100 elbo_samples
------------------------------------------------------------ 
EXPERIMENTAL ALGORITHM: 
  This procedure has not been thoroughly tested and may be unstable 
  or buggy. The interface is subject to change. 
------------------------------------------------------------ 
Gradient evaluation took 0.157354 seconds 
1000 transitions using 10 leapfrog steps per transition would take 1573.54 seconds. 
Adjust your expectations accordingly! 
Begin eta adaptation. 
Iteration:   1 / 250 [  0%]  (Adaptation) 
Iteration:  50 / 250 [ 20%]  (Adaptation) 
Iteration: 100 / 250 [ 40%]  (Adaptation) 
Iteration: 150 / 250 [ 60%]  (Adaptation) 
Iteration: 200 / 250 [ 80%]  (Adaptation) 
Iteration: 250 / 250 [100%]  (Adaptation) 
Success! Found best value [eta = 0.1]. 
Begin stochastic gradient ascent. 
  iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  
   100       -49977.519             1.000            1.000 
   200       -49765.863             0.502            1.000 
   300       -49699.416             0.335            0.004   MEDIAN ELBO CONVERGED 
Drawing a sample of size 1000 from the approximate posterior...  
COMPLETED. 
Finished in  236.0 seconds.
Fit succeeded in attempt 1
Inference completed successfully.
Scale for x is already present.
Adding another scale for x, which will replace the existing scale.
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
Attempt 1 with 10000 iterations, 1 grad_samples, and 100 elbo_samples
------------------------------------------------------------ 
EXPERIMENTAL ALGORITHM: 
  This procedure has not been thoroughly tested and may be unstable 
  or buggy. The interface is subject to change. 
------------------------------------------------------------ 
Gradient evaluation took 0.02251 seconds 
1000 transitions using 10 leapfrog steps per transition would take 225.1 seconds. 
Adjust your expectations accordingly! 
Begin eta adaptation. 
Iteration:   1 / 250 [  0%]  (Adaptation) 
Iteration:  50 / 250 [ 20%]  (Adaptation) 
Iteration: 100 / 250 [ 40%]  (Adaptation) 
Iteration: 150 / 250 [ 60%]  (Adaptation) 
Iteration: 200 / 250 [ 80%]  (Adaptation) 
Success! Found best value [eta = 1] earlier than expected. 
Begin stochastic gradient ascent. 
  iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  
   100       -49409.589             1.000            1.000 
   200       -49410.571             0.500            1.000 
   300       -49406.330             0.333            0.000   MEDIAN ELBO CONVERGED 
Drawing a sample of size 1000 from the approximate posterior...  
