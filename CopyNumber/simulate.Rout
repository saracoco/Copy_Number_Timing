
R version 4.3.3 (2024-02-29) -- "Angel Food Cake"
Copyright (C) 2024 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

[Previously saved workspace restored]

> library(patchwork)
> library(loo)
This is loo version 2.8.0
- Online documentation and vignettes at mc-stan.org/loo
- As of v2.0.0 loo defaults to 1 core but we recommend using as many as possible. Use the 'cores' argument or set options(mc.cores = NUM_CORES) for an entire session. 
> library(bayesplot)
This is bayesplot version 1.11.1
- Online documentation and vignettes at mc-stan.org/bayesplot
- bayesplot theme set to bayesplot::theme_default()
   * Does _not_ affect other ggplot2 plots
   * See ?bayesplot_theme_set for details on theme setting
> library(cmdstanr)
This is cmdstanr version 0.8.1
- CmdStanR documentation and vignettes: mc-stan.org/cmdstanr
- CmdStan path: /u/cdslab/scocomello/.cmdstan/cmdstan-2.34.1
- CmdStan version: 2.34.1

A newer version of CmdStan is available. See ?install_cmdstan() to install it.
To disable this check set option or environment variable cmdstanr_no_ver_check=TRUE.
> library(factoextra)
Loading required package: ggplot2
Welcome! Want to learn more? See two factoextra-related books at https://goo.gl/ve3WBa
> library(dplyr)

Attaching package: ‘dplyr’

The following objects are masked from ‘package:stats’:

    filter, lag

The following objects are masked from ‘package:base’:

    intersect, setdiff, setequal, union

> library(stringr) #for plotting add in the right script
> library(fossil) #RI and ARI computation
Loading required package: sp
Loading required package: maps
Loading required package: shapefiles
Loading required package: foreign

Attaching package: ‘shapefiles’

The following objects are masked from ‘package:foreign’:

    read.dbf, write.dbf

> library(gridExtra)

Attaching package: ‘gridExtra’

The following object is masked from ‘package:dplyr’:

    combine

> 
> 
> 
> #setwd("C:/Users/sarac/CDS_git/Copy-Number-Timing/CopyNumber/")
> #orfeo
> setwd("/orfeo/cephfs/scratch/cdslab/scocomello/Copy_Number_Timing/CopyNumber")
> 
> original_dir <- getwd()
> 
> source("./CNTiming/R/simulate_functions.R")
> source("./CNTiming/R/fitting_functions.R")
Loading required package: StanHeaders

rstan version 2.32.6 (Stan version 2.32.2)

For execution on a local, multicore CPU with excess RAM we recommend calling
options(mc.cores = parallel::detectCores()).
To avoid recompilation of unchanged Stan programs, we recommend calling
rstan_options(auto_write = TRUE)
For within-chain threading using `reduce_sum()` or `map_rect()` Stan functions,
change `threads_per_chain` option:
rstan_options(threads_per_chain = 1)


Attaching package: ‘tidyr’

The following object is masked from ‘package:rstan’:

    extract


Attaching package: ‘matrixStats’

The following object is masked from ‘package:dplyr’:

    count

> source("./CNTiming/R/plotting_functions.R")
> 
> 
> self_name = "try"
> new_dir = paste0("../",self_name) #relative path of the new created directory where to save the simulation results
> dir.create(new_dir)
Warning message:
In dir.create(new_dir) : '../try' already exists
> 
> number_events = 6
> number_clocks = 2
> 
> INIT = FALSE
> epsilon = 0.20
> n_simulations = 1
> purity = 0.99
> 
> vector_karyo <- c("2:0", "2:1", "2:2")
> weights_karyo <- c(0.33, 0.33, 0.33)
> 
> 
> # get simulation parametes
> coverage = 100 # average number of reads that align to a reference base
> mu = 1e-4 # mutation rate
> w = 1e-2 # cell division rate
> l = 1e7 # length of the segment
> time_interval = 20
> 
> 
> options(bitmapType='cairo')
> 
> 
> 
> 
> for(i in 1:n_simulations){
+   # Create a unique directory for each iteration
+   iter_dir <- paste0("/simulation_iteration_", i)
+   iter_dir <- paste0(new_dir,iter_dir)
+   dir.create(iter_dir)
+   setwd(iter_dir)
+   dir.create(paste0("./plots"), showWarnings = TRUE)
+   dir.create(paste0("./results"), showWarnings = FALSE)
+   
+   
+ 
+   vector_tau = rep(0, number_clocks)
+   
+   for (j in 1:number_clocks){
+     vector_tau[j] = runif(1, 0)
+     if (j != 1){
+       while (!all ( abs(vector_tau[1:j-1] - vector_tau[j]) > epsilon  )   ){
+         vector_tau[j] = runif(1, 0)
+       }
+     }
+   }
+   weights_tau <- rep(1/number_clocks, number_clocks)
+   
+   data <- get_taus_karyo(number_events, vector_tau, vector_karyo, weights_tau, weights_karyo)
+   simulation_data_all_segments = get_simulation(data$taus, data$karyo, purity, coverage = 100) # the other parameters have default value assigned if none is specified
+   simulation_data_all_segments <- simulation_data_all_segments[order(simulation_data_all_segments$segment_id), ]
+ 
+ 
+   saveRDS(simulation_data_all_segments, "./results/all_sim_input_prepare_input_data.rds")
+ 
+ 
+ 
+   
+   Subtitle <- vector("list", (length(unique(simulation_data_all_segments$segment_id))+1))
+   Subtitle[[1]]  <- paste0("Number of mutations per segment: ")
+   num_mutations_all_segments <- c()
+ 
+     for (i in seq_along(unique(simulation_data_all_segments$segment_id))) {
+     segment <- unique(simulation_data_all_segments$segment_id)[i]
+     num_mutations <- nrow(simulation_data_all_segments %>% filter(segment_id == segment))
+     num_mutations_all_segments <- c(num_mutations_all_segments, num_mutations)
+     Subtitle[[i+1]] <- paste0(segment, "=", num_mutations," ")
+   }
+   
+   Subtitle <- paste(Subtitle, collapse = "   ")
+   cat(Subtitle)
+ 
+   mean_mut <- mean(num_mutations_all_segments)
+   max_mut <- max(num_mutations_all_segments)
+   min_mut <- min(num_mutations_all_segments)
+ 
+   Subtitle_short <- paste0("Mutations per segment: average =", mean_mut, ",  min = ", min_mut, ", max = ", max_mut )
+ 
+ 
+   #add statistics on number of mutations from the simulation
+   
+   simulation_params <- list(
+     vector_tau = vector_tau,
+     vector_karyo = vector_karyo,
+     weights_tau = weights_tau,
+     weights_karyo = weights_karyo,
+     taus = data$taus,
+     karyo = data$karyo,
+     purity = purity,
+     number_events = number_events, # = nrow(vector-tau) / nrow(vector_karyo)
+     number_clocks = number_clocks, # = unique(vector_tau)
+     epsilon = epsilon
+   )
+ 
+ 
+ 
+ simulation_data_plot <- simulation_data_all_segments %>% mutate(tau = round(tau, 2))
+ 
+ plot_data <- simulation_data_plot %>%
+   ggplot(mapping = aes(x = NV / DP, fill = segment_name)) +
+   geom_histogram(alpha = 0.7, position = "identity", color = "black") + # Add borders for visibility
+   labs(
+     title = "Distribution on the VAF for each segment in the simulated data",
+     subtitle = paste0(Subtitle_short)
+   ) +
+   facet_wrap(vars(karyotype, tau, segment_name), scales = "free_x", strip.position = "bottom") +
+   theme_minimal() +
+   theme(
+     panel.background = element_rect(fill = "white", color = "grey90"),  # Light grey panel background
+     plot.background = element_rect(fill = "white", color = NA),   # White plot background
+     strip.background = element_rect(fill = "grey85", color = NA),  # Light strip background
+     strip.placement = "outside",   # Place facet labels outside
+     axis.text.x = element_text(angle = 45, hjust = 1, color = "black", size = 10),  # Rotate x-axis text for readability
+     axis.ticks.x = element_line(color = "black"),  # Black x-axis ticks
+     panel.spacing = unit(1.5, "lines"),  # Increase space between facets
+     strip.text.x = element_text(size = 11, color = "black", face = "bold"),  # Bold and adjust strip text
+     axis.line = element_line(color = "black"),  # Black axis lines
+     axis.title.x = element_text(color = "black", size = 12, face = "bold"),  # Bold x-axis title
+     axis.title.y = element_text(color = "black", size = 12, face = "bold")   # Bold y-axis title
+   )
+ 
+ 
+ 
+   #save plot of the simulated data in which we can see each single segment VAF distribution
+   ggsave("./plots/simulation_data.png", plot = plot_data, width = 8 + simulation_params$number_events, height = 6 + simulation_params$number_events + (simulation_params$number_events/1.3), limitsize = FALSE,   device = png) 
+   #simulation_params can be substituted in relation with simulation_data variables
+   
+   
+   #in "fit model selection best K" the plots for each K inference is directly saved 
+   results <- fit_model_selection_best_K(simulation_data_all_segments, data$karyo, purity, INIT = INIT, simulation_params = simulation_params)
+   saveRDS(results, paste0("./results/results_simulation",i,".rds"))
+   
+ 
+   
+   
+   
+   model_selection_plot = plotting_model_selection(results)
+   model_selection_plot
+   ggsave("./plots/model_selection_plot.png", plot = model_selection_plot, width = 12, height = 10,  device = png)
+   
+   model_selection <- results$model_selection_tibble
+   saveRDS(model_selection, "./results/model_selection.rds")
+   
+   
+   setwd(original_dir)
+   
+ }
Number of mutations per segment:    1=754    2=376    3=571    4=488    5=561    6=533 `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
these are the peaks used to filter out mutations 
          [,1]      [,2]
[1,] 0.2487437 0.4974874
[2,] 0.4950000 0.9900000
[3,] 0.3311037 0.6622074
[4,] 0.3311037 0.6622074
[5,] 0.2487437 0.4974874
[6,] 0.2487437 0.4974874
These are the Karyotypes extracted from the all_sim data, used in peaks
[1] "2:2" "2:0" "2:1" "2:1" "2:2" "2:2"
[1] 1 2 3 4 5 6
These are the Karyotypes directly from the simulation, used for peaks in the model
 [1] "2:2" "2:0" "2:1" "2:1" "2:2" "2:2"
These are the peaks which are passed in the inference task, more reliable let's say
          [,1]      [,2]
[1,] 0.2487437 0.4974874
[2,] 0.4950000 0.9900000
[3,] 0.3311037 0.6622074
[4,] 0.3311037 0.6622074
[5,] 0.2487437 0.4974874
[6,] 0.2487437 0.4974874
[1] "2:2" "2:0" "2:1" "2:1" "2:2" "2:2"
Attempt 1 of 4
Running inference, retry 1
------------------------------------------------------------ 
EXPERIMENTAL ALGORITHM: 
  This procedure has not been thoroughly tested and may be unstable 
  or buggy. The interface is subject to change. 
------------------------------------------------------------ 
Gradient evaluation took 0.002692 seconds 
1000 transitions using 10 leapfrog steps per transition would take 26.92 seconds. 
Adjust your expectations accordingly! 
Begin eta adaptation. 
Iteration:   1 / 250 [  0%]  (Adaptation) 
Iteration:  50 / 250 [ 20%]  (Adaptation) 
Iteration: 100 / 250 [ 40%]  (Adaptation) 
Iteration: 150 / 250 [ 60%]  (Adaptation) 
Iteration: 200 / 250 [ 80%]  (Adaptation) 
Success! Found best value [eta = 1] earlier than expected. 
Begin stochastic gradient ascent. 
  iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  
   100       -10215.953             1.000            1.000 
   200       -10214.679             0.500            1.000 
   300       -10215.794             0.333            0.000   MEDIAN ELBO CONVERGED 
Drawing a sample of size 1000 from the approximate posterior...  
COMPLETED. 
Finished in  11.0 seconds.
ELBO for this run: -10215.3609
Attempt 2 of 4
Running inference, retry 1
------------------------------------------------------------ 
EXPERIMENTAL ALGORITHM: 
  This procedure has not been thoroughly tested and may be unstable 
  or buggy. The interface is subject to change. 
------------------------------------------------------------ 
Gradient evaluation took 0.002537 seconds 
1000 transitions using 10 leapfrog steps per transition would take 25.37 seconds. 
Adjust your expectations accordingly! 
Begin eta adaptation. 
Iteration:   1 / 250 [  0%]  (Adaptation) 
Iteration:  50 / 250 [ 20%]  (Adaptation) 
Iteration: 100 / 250 [ 40%]  (Adaptation) 
Iteration: 150 / 250 [ 60%]  (Adaptation) 
Iteration: 200 / 250 [ 80%]  (Adaptation) 
Success! Found best value [eta = 1] earlier than expected. 
Begin stochastic gradient ascent. 
  iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  
   100       -10215.036             1.000            1.000 
   200       -10215.218             0.500            1.000 
   300       -10214.761             0.333            0.000   MEDIAN ELBO CONVERGED 
Drawing a sample of size 1000 from the approximate posterior...  
COMPLETED. 
Finished in  10.4 seconds.
ELBO for this run: -10214.2036
Attempt 3 of 4
Running inference, retry 1
------------------------------------------------------------ 
EXPERIMENTAL ALGORITHM: 
  This procedure has not been thoroughly tested and may be unstable 
  or buggy. The interface is subject to change. 
------------------------------------------------------------ 
Gradient evaluation took 0.002538 seconds 
1000 transitions using 10 leapfrog steps per transition would take 25.38 seconds. 
Adjust your expectations accordingly! 
Begin eta adaptation. 
Iteration:   1 / 250 [  0%]  (Adaptation) 
Iteration:  50 / 250 [ 20%]  (Adaptation) 
Iteration: 100 / 250 [ 40%]  (Adaptation) 
Iteration: 150 / 250 [ 60%]  (Adaptation) 
Iteration: 200 / 250 [ 80%]  (Adaptation) 
Success! Found best value [eta = 1] earlier than expected. 
Begin stochastic gradient ascent. 
  iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  
   100       -10215.685             1.000            1.000 
   200       -10216.612             0.500            1.000 
   300       -10214.609             0.333            0.000   MEDIAN ELBO CONVERGED 
Drawing a sample of size 1000 from the approximate posterior...  
COMPLETED. 
Finished in  11.7 seconds.
ELBO for this run: -10214.2736
Attempt 4 of 4
Running inference, retry 1
------------------------------------------------------------ 
EXPERIMENTAL ALGORITHM: 
  This procedure has not been thoroughly tested and may be unstable 
  or buggy. The interface is subject to change. 
------------------------------------------------------------ 
Gradient evaluation took 0.002478 seconds 
1000 transitions using 10 leapfrog steps per transition would take 24.78 seconds. 
Adjust your expectations accordingly! 
Begin eta adaptation. 
Iteration:   1 / 250 [  0%]  (Adaptation) 
Iteration:  50 / 250 [ 20%]  (Adaptation) 
Iteration: 100 / 250 [ 40%]  (Adaptation) 
Iteration: 150 / 250 [ 60%]  (Adaptation) 
Iteration: 200 / 250 [ 80%]  (Adaptation) 
Success! Found best value [eta = 1] earlier than expected. 
Begin stochastic gradient ascent. 
  iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  
   100       -10214.710             1.000            1.000 
   200       -10214.890             0.500            1.000 
   300       -10214.740             0.333            0.000   MEDIAN ELBO CONVERGED 
Drawing a sample of size 1000 from the approximate posterior...  
COMPLETED. 
Finished in  10.6 seconds.
ELBO for this run: -10215.0306
Best ELBO after 4 attempts: -10214.2036
 loglik = likelihood value from generated quantities-3.254278 1000 3138log_lik_total_per_sample = mean of likelihood value from generated quantities1000L = mean of likelihood value from generated quantities-10211.92[1] "dim of log_lik_matrix3138" "dim of log_lik_matrix2"   
[1] "dim of marginalized_log_lik3138" "dim of marginalized_log_lik2"   
[1] "dim of responsibilities3138" "dim of responsibilities2"   
Scale for x is already present.
Adding another scale for x, which will replace the existing scale.
Scale for x is already present.
Adding another scale for x, which will replace the existing scale.
Number of mutations per segment:    segment 1=722    segment 2=357    segment 3=539    segment 4=469    segment 5=539    segment 6=512 `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
Number of mutations per segment:    1=754    2=376    3=571    4=488    5=561    6=533 `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
these are the peaks used to filter out mutations 
          [,1]      [,2]
[1,] 0.2487437 0.4974874
[2,] 0.4950000 0.9900000
[3,] 0.3311037 0.6622074
[4,] 0.3311037 0.6622074
[5,] 0.2487437 0.4974874
[6,] 0.2487437 0.4974874
These are the Karyotypes extracted from the all_sim data, used in peaks
[1] "2:2" "2:0" "2:1" "2:1" "2:2" "2:2"
[1] 1 2 3 4 5 6
These are the Karyotypes directly from the simulation, used for peaks in the model
 [1] "2:2" "2:0" "2:1" "2:1" "2:2" "2:2"
These are the peaks which are passed in the inference task, more reliable let's say
          [,1]      [,2]
[1,] 0.2487437 0.4974874
[2,] 0.4950000 0.9900000
[3,] 0.3311037 0.6622074
[4,] 0.3311037 0.6622074
[5,] 0.2487437 0.4974874
[6,] 0.2487437 0.4974874
[1] "2:2" "2:0" "2:1" "2:1" "2:2" "2:2"
Attempt 1 of 4
Running inference, retry 1
------------------------------------------------------------ 
EXPERIMENTAL ALGORITHM: 
  This procedure has not been thoroughly tested and may be unstable 
  or buggy. The interface is subject to change. 
------------------------------------------------------------ 
Gradient evaluation took 0.004471 seconds 
1000 transitions using 10 leapfrog steps per transition would take 44.71 seconds. 
Adjust your expectations accordingly! 
Begin eta adaptation. 
Iteration:   1 / 250 [  0%]  (Adaptation) 
Iteration:  50 / 250 [ 20%]  (Adaptation) 
Iteration: 100 / 250 [ 40%]  (Adaptation) 
Iteration: 150 / 250 [ 60%]  (Adaptation) 
Iteration: 200 / 250 [ 80%]  (Adaptation) 
Success! Found best value [eta = 1] earlier than expected. 
Begin stochastic gradient ascent. 
  iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  
   100        -9949.976             1.000            1.000 
   200        -9948.633             0.500            1.000 
   300        -9949.529             0.333            0.000   MEDIAN ELBO CONVERGED 
Drawing a sample of size 1000 from the approximate posterior...  
COMPLETED. 
Finished in  16.9 seconds.
ELBO for this run: -9955.07836
Attempt 2 of 4
Running inference, retry 1
------------------------------------------------------------ 
EXPERIMENTAL ALGORITHM: 
  This procedure has not been thoroughly tested and may be unstable 
  or buggy. The interface is subject to change. 
------------------------------------------------------------ 
Gradient evaluation took 0.004468 seconds 
1000 transitions using 10 leapfrog steps per transition would take 44.68 seconds. 
Adjust your expectations accordingly! 
Begin eta adaptation. 
Iteration:   1 / 250 [  0%]  (Adaptation) 
Iteration:  50 / 250 [ 20%]  (Adaptation) 
Iteration: 100 / 250 [ 40%]  (Adaptation) 
Iteration: 150 / 250 [ 60%]  (Adaptation) 
Iteration: 200 / 250 [ 80%]  (Adaptation) 
Success! Found best value [eta = 1] earlier than expected. 
Begin stochastic gradient ascent. 
  iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  
   100        -9950.207             1.000            1.000 
   200        -9949.812             0.500            1.000 
   300        -9947.313             0.333            0.000   MEDIAN ELBO CONVERGED 
Drawing a sample of size 1000 from the approximate posterior...  
COMPLETED. 
Finished in  15.8 seconds.
ELBO for this run: -9954.34379
Attempt 3 of 4
Running inference, retry 1
------------------------------------------------------------ 
EXPERIMENTAL ALGORITHM: 
  This procedure has not been thoroughly tested and may be unstable 
  or buggy. The interface is subject to change. 
------------------------------------------------------------ 
Gradient evaluation took 0.004587 seconds 
1000 transitions using 10 leapfrog steps per transition would take 45.87 seconds. 
Adjust your expectations accordingly! 
Begin eta adaptation. 
Iteration:   1 / 250 [  0%]  (Adaptation) 
Iteration:  50 / 250 [ 20%]  (Adaptation) 
Iteration: 100 / 250 [ 40%]  (Adaptation) 
Iteration: 150 / 250 [ 60%]  (Adaptation) 
Iteration: 200 / 250 [ 80%]  (Adaptation) 
Success! Found best value [eta = 1] earlier than expected. 
Begin stochastic gradient ascent. 
  iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  
   100        -9951.037             1.000            1.000 
   200        -9949.118             0.500            1.000 
   300        -9947.796             0.333            0.000   MEDIAN ELBO CONVERGED 
Drawing a sample of size 1000 from the approximate posterior...  
COMPLETED. 
Finished in  15.5 seconds.
ELBO for this run: -9955.25638
Attempt 4 of 4
Running inference, retry 1
------------------------------------------------------------ 
EXPERIMENTAL ALGORITHM: 
  This procedure has not been thoroughly tested and may be unstable 
  or buggy. The interface is subject to change. 
------------------------------------------------------------ 
Gradient evaluation took 0.004541 seconds 
1000 transitions using 10 leapfrog steps per transition would take 45.41 seconds. 
Adjust your expectations accordingly! 
Begin eta adaptation. 
Iteration:   1 / 250 [  0%]  (Adaptation) 
Iteration:  50 / 250 [ 20%]  (Adaptation) 
Iteration: 100 / 250 [ 40%]  (Adaptation) 
Iteration: 150 / 250 [ 60%]  (Adaptation) 
Iteration: 200 / 250 [ 80%]  (Adaptation) 
Success! Found best value [eta = 1] earlier than expected. 
Begin stochastic gradient ascent. 
  iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  
   100        -9949.806             1.000            1.000 
   200        -9949.881             0.500            1.000 
   300        -9947.658             0.333            0.000   MEDIAN ELBO CONVERGED 
Drawing a sample of size 1000 from the approximate posterior...  
COMPLETED. 
Finished in  16.8 seconds.
ELBO for this run: -9953.76723
Best ELBO after 4 attempts: -9953.76723
 loglik = likelihood value from generated quantities-3.163743 1000 3138log_lik_total_per_sample = mean of likelihood value from generated quantities1000L = mean of likelihood value from generated quantities-9927.825[1] "dim of log_lik_matrix3138" "dim of log_lik_matrix4"   
[1] "dim of marginalized_log_lik3138" "dim of marginalized_log_lik2"   
[1] "dim of responsibilities3138" "dim of responsibilities2"   
Scale for x is already present.
Adding another scale for x, which will replace the existing scale.
Scale for x is already present.
Adding another scale for x, which will replace the existing scale.
Number of mutations per segment:    segment 1=722    segment 2=357    segment 3=539    segment 4=469    segment 5=539    segment 6=512 `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
Number of mutations per segment:    1=754    2=376    3=571    4=488    5=561    6=533 `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
these are the peaks used to filter out mutations 
          [,1]      [,2]
[1,] 0.2487437 0.4974874
[2,] 0.4950000 0.9900000
[3,] 0.3311037 0.6622074
[4,] 0.3311037 0.6622074
[5,] 0.2487437 0.4974874
[6,] 0.2487437 0.4974874
These are the Karyotypes extracted from the all_sim data, used in peaks
[1] "2:2" "2:0" "2:1" "2:1" "2:2" "2:2"
[1] 1 2 3 4 5 6
These are the Karyotypes directly from the simulation, used for peaks in the model
 [1] "2:2" "2:0" "2:1" "2:1" "2:2" "2:2"
These are the peaks which are passed in the inference task, more reliable let's say
          [,1]      [,2]
[1,] 0.2487437 0.4974874
[2,] 0.4950000 0.9900000
[3,] 0.3311037 0.6622074
[4,] 0.3311037 0.6622074
[5,] 0.2487437 0.4974874
[6,] 0.2487437 0.4974874
[1] "2:2" "2:0" "2:1" "2:1" "2:2" "2:2"
Attempt 1 of 4
Running inference, retry 1
------------------------------------------------------------ 
EXPERIMENTAL ALGORITHM: 
  This procedure has not been thoroughly tested and may be unstable 
  or buggy. The interface is subject to change. 
------------------------------------------------------------ 
Gradient evaluation took 0.004486 seconds 
1000 transitions using 10 leapfrog steps per transition would take 44.86 seconds. 
Adjust your expectations accordingly! 
Begin eta adaptation. 
Iteration:   1 / 250 [  0%]  (Adaptation) 
Iteration:  50 / 250 [ 20%]  (Adaptation) 
Iteration: 100 / 250 [ 40%]  (Adaptation) 
Iteration: 150 / 250 [ 60%]  (Adaptation) 
Iteration: 200 / 250 [ 80%]  (Adaptation) 
Success! Found best value [eta = 1] earlier than expected. 
Begin stochastic gradient ascent. 
  iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  
   100        -9948.959             1.000            1.000 
   200        -9948.237             0.500            1.000 
   300        -9949.400             0.333            0.000   MEDIAN ELBO CONVERGED 
Drawing a sample of size 1000 from the approximate posterior...  
COMPLETED. 
Finished in  16.9 seconds.
ELBO for this run: -9956.08935
Attempt 2 of 4
Running inference, retry 1
------------------------------------------------------------ 
EXPERIMENTAL ALGORITHM: 
  This procedure has not been thoroughly tested and may be unstable 
  or buggy. The interface is subject to change. 
------------------------------------------------------------ 
Gradient evaluation took 0.004495 seconds 
1000 transitions using 10 leapfrog steps per transition would take 44.95 seconds. 
Adjust your expectations accordingly! 
Begin eta adaptation. 
Iteration:   1 / 250 [  0%]  (Adaptation) 
Iteration:  50 / 250 [ 20%]  (Adaptation) 
Iteration: 100 / 250 [ 40%]  (Adaptation) 
Iteration: 150 / 250 [ 60%]  (Adaptation) 
Iteration: 200 / 250 [ 80%]  (Adaptation) 
Success! Found best value [eta = 1] earlier than expected. 
Begin stochastic gradient ascent. 
  iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  
   100        -9948.904             1.000            1.000 
   200        -9950.282             0.500            1.000 
   300        -9947.721             0.333            0.000   MEDIAN ELBO CONVERGED 
Drawing a sample of size 1000 from the approximate posterior...  
COMPLETED. 
Finished in  15.3 seconds.
ELBO for this run: -9954.90079
Attempt 3 of 4
Running inference, retry 1
------------------------------------------------------------ 
EXPERIMENTAL ALGORITHM: 
  This procedure has not been thoroughly tested and may be unstable 
  or buggy. The interface is subject to change. 
------------------------------------------------------------ 
Gradient evaluation took 0.004436 seconds 
1000 transitions using 10 leapfrog steps per transition would take 44.36 seconds. 
Adjust your expectations accordingly! 
Begin eta adaptation. 
Iteration:   1 / 250 [  0%]  (Adaptation) 
Iteration:  50 / 250 [ 20%]  (Adaptation) 
Iteration: 100 / 250 [ 40%]  (Adaptation) 
Iteration: 150 / 250 [ 60%]  (Adaptation) 
Iteration: 200 / 250 [ 80%]  (Adaptation) 
Success! Found best value [eta = 1] earlier than expected. 
Begin stochastic gradient ascent. 
  iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  
   100        -9953.178             1.000            1.000 
   200        -9949.108             0.500            1.000 
   300        -9947.746             0.334            0.000   MEDIAN ELBO CONVERGED 
Drawing a sample of size 1000 from the approximate posterior...  
COMPLETED. 
Finished in  16.2 seconds.
ELBO for this run: -9954.00224
Attempt 4 of 4
Running inference, retry 1
------------------------------------------------------------ 
EXPERIMENTAL ALGORITHM: 
  This procedure has not been thoroughly tested and may be unstable 
  or buggy. The interface is subject to change. 
------------------------------------------------------------ 
Gradient evaluation took 0.004328 seconds 
1000 transitions using 10 leapfrog steps per transition would take 43.28 seconds. 
Adjust your expectations accordingly! 
Begin eta adaptation. 
Iteration:   1 / 250 [  0%]  (Adaptation) 
Iteration:  50 / 250 [ 20%]  (Adaptation) 
Iteration: 100 / 250 [ 40%]  (Adaptation) 
Iteration: 150 / 250 [ 60%]  (Adaptation) 
Iteration: 200 / 250 [ 80%]  (Adaptation) 
Success! Found best value [eta = 1] earlier than expected. 
Begin stochastic gradient ascent. 
  iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes  
   100        -9948.404             1.000            1.000 
   200        -9950.760             0.500            1.000 
   300        -9947.865             0.334            0.000   MEDIAN ELBO CONVERGED 
Drawing a sample of size 1000 from the approximate posterior...  
COMPLETED. 
Finished in  15.7 seconds.
ELBO for this run: -9955.47558
Best ELBO after 4 attempts: -9954.00224
Scale for x is already present.
Adding another scale for x, which will replace the existing scale.
Number of mutations per segment:    segment 1=722    segment 2=357    segment 3=539    segment 4=469    segment 5=539    segment 6=512 `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
Number of mutations per segment:    1=754    2=376    3=571    4=488    5=561    6=533 `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
There were 24 warnings (use warnings() to see them)
> 
> 
> proc.time()
   user  system elapsed 
634.132  34.663 678.820 
